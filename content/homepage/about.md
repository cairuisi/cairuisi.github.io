---
title: Ruisi Cai
draft: false
role: Ph.D Student
avatar: images/Ruisi.jpg
bio: 
organization:
  name: UT Austin
  url: https://www.utexas.edu/
social:
  - icon: envelope
    iconPack: fas
    url: mailto:ruisi.cai@utexas.edu
  - icon: twitter
    iconPack: fab
    url: https://twitter.com/ccccrs_0908
  - icon: github
    iconPack: fab
    url: https://github.com/cairuisi

weight: 1
widget:
  handler: about

  # Options: sm, md, lg and xl. Default is md.
  width:

  sidebar:
    # Options: left and right. Leave blank to hide.
    position:
    # Options: sm, md, lg and xl. Default is md.
    scale:
  
  background:
    # Options: primary, secondary, tertiary or any valid color value. Default is primary.
    color: secondary
    image:
    # Options: auto, cover and contain. Default is auto.
    size:
    # Options: center, top, right, bottom, left.
    position:
    # Options: fixed, local, scroll.
    attachment: 
---

## About Me

I'm a second year Ph.D. student in the [VITA Group](https://vita-group.github.io/) of [Electrical and Computer Engineering Department](https://www.ece.utexas.edu/), [the Univeristiy of Texas at Austin](https://www.utexas.edu/), under the supervision of Prof. Zhangyang (Atlas) Wang. Prior to that, I obatined my B.E. degree from [University of Science and Technology of China (USTC)](http://en.ustc.edu.cn/). [[CV]](https://drive.google.com/file/d/1jDtj22gmze4FW69HvT2HnUB8u0Htea0_/view?usp=sharing)

I'm currently working on <u>machine learning </u>, with research focus on: 
* **Efficient Model Training**: Mixture of Experts (MoE), Model Merging & Recycling
* **Trustworthy Machine Learning System**: Adversarial Robustness, Data Poisoning, Federated Learning

## NEWS
* May, 2024. My intern project at NVIDIA "Flextron: Many-in-One Flexible Large Language Model" is accepted for Oral Presentation at **ICML2024**!
* May, 2024. "LoCoCo: Dropping In Convolutions for Long Context Compression" is accepted by **ICML2024**!
* Feb, 2024. My teammate, [Yeonju Ro](https://sites.google.com/view/hey-yeonju), and I have been chosen as finalists for the 2024 Qualcomm Innovation Fellowship.
* Sep, 2023. I've just begun my incredible internship journey in NVIDIA.
* Sep, 2023. "$\mathrm{H_2O}$: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models" is accepted by **NeurIPS2023**!
* Jul, 2023. "Robust Mixture-of-Expert Training for Convolutional Neural Networks" is accepted by **ICCV2023**!
* Apr, 2023. "Robust Weight Signatures: Gaining Robustness as Easy as Patching Weights?" is accepted by **ICML2023**!
* Sep, 2022. "Randomized Channel Shuffling: Minimal-Overhead Backdoor Attack Detection without Clean Datasets" is accepted by **NeurIPS2022**!

## Publication List
(A superscript * denotes equal contribution)

**Flextron: Many-in-One Flexible Large Language Model**  
**Ruisi Cai**, Saurav Muralidharan, Greg Heinrich, Hongxu Yin, Zhangyang Wang, Jan Kautz, Pavlo Molchanov  
*ICML2024: International Conference on Machine Learning <span style="color:red">(Oral)</span>*, [\[Paper\]](https://arxiv.org/pdf/2406.10260) [\[Project\]](https://cairuisi.github.io/Flextron/)

**LoCoCo: Dropping In Convolutions for Long Context Compression**  
**Ruisi Cai**, Yuandong Tian, Zhangyang Wang, Beidi Chen  
*ICML2024: International Conference on Machine Learning*, [\[Paper\]](https://arxiv.org/abs/2406.05317) [\[Code\]](https://github.com/VITA-Group/LoCoCo)

**Robust Mixture-of-Expert Training for Convolutional Neural Networks**  
Yihua Zhang, **Ruisi Cai**, Tianlong Chen, Guanhua Zhang, Huan Zhang, Pin-Yu Chen, Shiyu Chang, Zhangyang Wang, Sijia Liu  
*ICCV2023: International Conference on Computer Vision <span style="color:red">(Oral)</span>* [\[Paper\]](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Mixture-of-Expert_Training_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf) [\[Code\]](https://github.com/optml-group/robust-moe-cnn)

**$\mathrm{H_2O}$: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models**   
Zhenyu Zhang, Ying Sheng, Tianyi Zhou, Tianlong Chen, Lianmin Zheng, **Ruisi Cai**, Zhao Song, Yuandong Tian, Christopher RÃ©, Clark Barrett, Zhangyang Wang, Beidi Chen  
*NeurIPS2023: Conference on Neural Information Processing Systems*, [\[Paper\]](https://arxiv.org/pdf/2306.14048.pdf) [\[Code\]](https://github.com/FMInference/H2O)

**Robust Weight Signatures: Gaining Robustness as Easy as Patching Weights?**  
**Ruisi Cai**, Zhenyu Zhang, Zhangyang Wang  
*ICML2023: International Conference on Machine Learning* [\[Paper\]](https://arxiv.org/pdf/2302.12480) [\[Code\]](https://github.com/VITA-Group/Robust_Weight_Signatures)

**Many-Task Federated Learning: A New Problem Setting and a Simple Baseline**  
**Ruisi Cai**, Xiaohan Chen, Shiwei Liu, Jayanth Srinivasa, Myungjin Lee, Ramana Kompella, Zhangyang Wang  
*CVPRW: 2nd Workshop on Federated Learning for Computer Vision* [\[Paper\]](https://openaccess.thecvf.com/content/CVPR2023W/FedVision/papers/Cai_Many-Task_Federated_Learning_A_New_Problem_Setting_and_a_Simple_CVPRW_2023_paper.pdf)

**Randomized Channel Shuffling: Minimal-Overhead Backdoor Attack Detection without Clean Datasets**  
**Ruisi Cai\***, Zhenyu Zhang\*, Tianlong Chen, Xiaohan Chen, Zhangyang Wang  
*NeurIPS2022: Conference on Neural Information Processing Systems* [\[Paper\]](https://proceedings.neurips.cc/paper_files/paper/2022/file/db1d5c63576587fc1d40d33a75190c71-Paper-Conference.pdf) [\[Code\]](https://github.com/VITA-Group/Random-Shuffling-BackdoorDetect)
