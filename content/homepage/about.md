---
title: Ruisi Cai
draft: false
role: Ph.D Student
avatar: images/Ruisi.jpg
bio: 
organization:
  name: UT Austin
  url: https://www.utexas.edu/
social:
  - icon: envelope
    iconPack: fas
    url: mailto:ruisi.cai@utexas.edu
  - icon: twitter
    iconPack: fab
    url: https://twitter.com/ccccrs_0908
  - icon: github
    iconPack: fab
    url: https://github.com/cairuisi

weight: 1
widget:
  handler: about

  # Options: sm, md, lg and xl. Default is md.
  width:

  sidebar:
    # Options: left and right. Leave blank to hide.
    position:
    # Options: sm, md, lg and xl. Default is md.
    scale:
  
  background:
    # Options: primary, secondary, tertiary or any valid color value. Default is primary.
    color: secondary
    image:
    # Options: auto, cover and contain. Default is auto.
    size:
    # Options: center, top, right, bottom, left.
    position:
    # Options: fixed, local, scroll.
    attachment: 
---

## About Me

I'm a third year Ph.D. student in the [VITA Group](https://vita-group.github.io/) of [Electrical and Computer Engineering Department](https://www.ece.utexas.edu/), [the Univeristiy of Texas at Austin](https://www.utexas.edu/), under the supervision of Prof. Zhangyang (Atlas) Wang. Prior to that, I obatined my B.E. degree from [University of Science and Technology of China (USTC)](http://en.ustc.edu.cn/).

I'm currently working on machine learning, with research focus on: 
* **Efficient training and inference for large foundation models**: 
  - Adaptive Framework: Elastic Model for Adaptive Deployment, Mixture of Experts (MoE)
  - Long Context Generation: Long Context Training \& Serving, State Space Model (SSM)
* **AI security and privacy**: 
  - Trustworthy ML, Robustness for Mixture of Experts (MoE), Backdoor Attack
  - Distributed Training, Task Heterogeneity, Data Scaling

## NEWS
* Mar. 2025. Excited to share that I have been selected to receive the ML and Systems Rising Star Awards 2025.
* Feb. 2025. Began my exciting internship in Citadel Securities.
* Dec. 2024. Excited to announce that I have been selected as a recipient of the [NVIDIA Fellowship](https://blogs.nvidia.com/blog/graduate-fellowship-recipients-2025-2026/). Thank you, NVIDIA! ðŸ’š
* Sep, 2024. "READ-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design" is accepted by  **NeurIPS2024**. 
* Sep, 2024. "Model-GLUE: Democratized LLM Scaling for A Large Model Zoo in the Wild" is accepted by  **NeurIPS2024** D&B track.
* May, 2024. My intern project at NVIDIA "Flextron: Many-in-One Flexible Large Language Model" is accepted for Oral Presentation at **ICML2024**! Check out our work at [\[Project Page\]](https://cairuisi.github.io/Flextron/)!
* May, 2024. "LoCoCo: Dropping In Convolutions for Long Context Compression" is accepted by **ICML2024**!
* Feb, 2024. My teammate, [Yeonju Ro](https://sites.google.com/view/hey-yeonju), and I have been chosen as finalists for the 2024 Qualcomm Innovation Fellowship.
* Sep, 2023. I've just begun my incredible internship journey in NVIDIA.
* Sep, 2023. "$\mathrm{H_2O}$: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models" is accepted by **NeurIPS2023**!
* Jul, 2023. "Robust Mixture-of-Expert Training for Convolutional Neural Networks" is accepted by **ICCV2023**!
* Apr, 2023. "Robust Weight Signatures: Gaining Robustness as Easy as Patching Weights?" is accepted by **ICML2023**!
* Sep, 2022. "Randomized Channel Shuffling: Minimal-Overhead Backdoor Attack Detection without Clean Datasets" is accepted by **NeurIPS2022**!

## Publication List
(A superscript * denotes equal contribution)

**Rethinking Addressing in Language Models via Contextualized Equivariant Positional Encoding**  
Jiajun Zhu, Peihao Wang, **Ruisi Cai**, Jason D. Lee, Zhangyang Wang, Pan Li  
*ICML2025: International Conference on Machine Learning*, [\[Paper\]](https://arxiv.org/pdf/2501.00712)

**FlexGS: Train Once, Deploy Everywhere with Many-in-One Flexible 3D Gaussian Splatting**  
Hengyu Liu, Yuehao Wang, Chenxin Li, **Ruisi Cai**, Kevin Wang, Wuyang Li, Pavlo Molchanov, Peihao Wang, Zhangyang Wang  
*CVPR2025: IEEE Conference on Computer Vision and Pattern Recognition*  

**Steepest Descent Density Control for Compact 3D Gaussian Splatting**  
Peihao Wang, Yuehao Wang, Dilin Wang, Sreyas Mohan, Zhiwen Fan, Lemeng Wu, **Ruisi Cai**, Yu-Ying Yeh, Zhangyang Wang, qiang liu, Rakesh Ranjan  
*CVPR2025: IEEE Conference on Computer Vision and Pattern Recognition*

**LLaMaFlex: Many-in-one LLMs via Generalized Pruning and Weight Sharing**  
**Ruisi Cai**, Saurav Muralidharan, Greg Heinrich, Hongxu Yin, Zhangyang Wang, Jan Kautz, Pavlo Molchanov  
*ICLR2025: International Conference on Learning Representations*, [\[Paper\]](https://openreview.net/pdf?id=AyC4uxx2HW) 

**Understanding Bottlenecks of State Space Models through the Lens of Recency and Over-smoothing**  
Peihao Wang, **Ruisi Cai**, Yuehao Wang, Jiajun Zhu, Pragya Srivastava, Zhangyang Wang, Pan Li  
*ICLR2025: International Conference on Learning Representations*, [\[Paper\]](https://arxiv.org/pdf/2501.00658)

**READ-ME: Refactorizing LLMs as Router-Decoupled Mixture of Experts with System Co-Design**    
**Ruisi Cai\***, Yeonju Ro\*, Geon-Woo Kim, Peihao Wang, Babak Ehteshami Bejnordi, Aditya Akella, Zhangyang Wang  
*NeurIPS2024: Conference on Neural Information Processing Systems*, [\[Paper\]](https://arxiv.org/pdf/2410.19123) [\[Code\]](https://github.com/VITA-Group/READ-ME) 

**Model-GLUE: Democratized LLM Scaling for A Large Model Zoo in the Wild**   
Xinyu Zhao\*, Guoheng Sun\*, **Ruisi Cai\***, Yukun Zhou\*, Pingzhi Li\*, Peihao Wang\*, Bowen Tan, Yexiao He, Li Chen, Yi Liang, Beidi Chen, Binhang Yuan, Hongyi Wang, Ang Li, Zhangyang Wang, Tianlong Chen  
*NeurIPS2024 D&B: Datasets and Benchmarks Track, Conference on Neural Information Processing Systems*, [\[Paper\]](https://arxiv.org/pdf/2410.05357) [\[Code\]](https://github.com/Model-GLUE/Model-GLUE)   

**Flextron: Many-in-One Flexible Large Language Model**  
**Ruisi Cai**, Saurav Muralidharan, Greg Heinrich, Hongxu Yin, Zhangyang Wang, Jan Kautz, Pavlo Molchanov  
*ICML2024: International Conference on Machine Learning <span style="color:red">(Oral)</span>*, [\[Paper\]](https://arxiv.org/pdf/2406.10260) [\[Project\]](https://cairuisi.github.io/Flextron/)

**LoCoCo: Dropping In Convolutions for Long Context Compression**  
**Ruisi Cai**, Yuandong Tian, Zhangyang Wang, Beidi Chen  
*ICML2024: International Conference on Machine Learning*, [\[Paper\]](https://arxiv.org/abs/2406.05317) [\[Code\]](https://github.com/VITA-Group/LoCoCo)

**Robust Mixture-of-Expert Training for Convolutional Neural Networks**  
Yihua Zhang, **Ruisi Cai**, Tianlong Chen, Guanhua Zhang, Huan Zhang, Pin-Yu Chen, Shiyu Chang, Zhangyang Wang, Sijia Liu  
*ICCV2023: International Conference on Computer Vision <span style="color:red">(Oral)</span>* [\[Paper\]](https://openaccess.thecvf.com/content/ICCV2023/papers/Zhang_Robust_Mixture-of-Expert_Training_for_Convolutional_Neural_Networks_ICCV_2023_paper.pdf) [\[Code\]](https://github.com/optml-group/robust-moe-cnn)

**$\mathrm{H_2O}$: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models**   
Zhenyu Zhang, Ying Sheng, Tianyi Zhou, Tianlong Chen, Lianmin Zheng, **Ruisi Cai**, Zhao Song, Yuandong Tian, Christopher RÃ©, Clark Barrett, Zhangyang Wang, Beidi Chen  
*NeurIPS2023: Conference on Neural Information Processing Systems*, [\[Paper\]](https://arxiv.org/pdf/2306.14048.pdf) [\[Code\]](https://github.com/FMInference/H2O)

**Robust Weight Signatures: Gaining Robustness as Easy as Patching Weights?**  
**Ruisi Cai**, Zhenyu Zhang, Zhangyang Wang  
*ICML2023: International Conference on Machine Learning* [\[Paper\]](https://arxiv.org/pdf/2302.12480) [\[Code\]](https://github.com/VITA-Group/Robust_Weight_Signatures)

**Many-Task Federated Learning: A New Problem Setting and a Simple Baseline**  
**Ruisi Cai**, Xiaohan Chen, Shiwei Liu, Jayanth Srinivasa, Myungjin Lee, Ramana Kompella, Zhangyang Wang  
*CVPRW: 2nd Workshop on Federated Learning for Computer Vision* [\[Paper\]](https://openaccess.thecvf.com/content/CVPR2023W/FedVision/papers/Cai_Many-Task_Federated_Learning_A_New_Problem_Setting_and_a_Simple_CVPRW_2023_paper.pdf)

**Randomized Channel Shuffling: Minimal-Overhead Backdoor Attack Detection without Clean Datasets**  
**Ruisi Cai\***, Zhenyu Zhang\*, Tianlong Chen, Xiaohan Chen, Zhangyang Wang  
*NeurIPS2022: Conference on Neural Information Processing Systems* [\[Paper\]](https://proceedings.neurips.cc/paper_files/paper/2022/file/db1d5c63576587fc1d40d33a75190c71-Paper-Conference.pdf) [\[Code\]](https://github.com/VITA-Group/Random-Shuffling-BackdoorDetect)
